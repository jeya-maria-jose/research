<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #2d59eb;
      text-decoration: none;
    }
    b {
      color: #e3124a;
      text-decoration: none;
    }
	  c {
      color: #21bf28;
      text-decoration: none;
    }
    a:focus,
    a:hover {
      color: #af19bf;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    span.highlight {
      background-color: #daa5e0;
    }
  </style>
  <link rel="icon" type="image/png" href="images/jose/jhuicon.png">
  <title>Jeya Maria Jose</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Jeya Maria Jose</name>
              </p>
              <p>Hi!, I am a 3rd year Ph.D. student at <a href="https://www.jhu.edu/">Johns Hopkins University</a>, in the Department of <a href="https://engineering.jhu.edu/ece/">Electrical and Computer Engineering</a> where I am working in <a href="https://engineering.jhu.edu/vpatel36/"> Vision and Image Understanding Lab </a>, advised by <a href="https://scholar.google.com/citations?user=AkEXTbIAAAAJ&hl=en"> Dr. Vishal M Patel </a>. </p> 
		      
		     <p> My research focus lies within the intersection of Computer Vision, Machine Learning, and Medical Imaging. More specifically, I work on image/3D segmentation, image enhancement, image-to-image translation for large-scale vision and medical imaging tasks.  </p>
		    </p>  
		    
		<p> I interned at <a href="https://research.adobe.com/"> Adobe </a> in the summer of 2021 where I worked on image harmonization problems. During my undergrad days, I worked at the <a href="http://bioeng.nus.edu.sg/mm/">Medical Mechatronics Lab</a> in <a href="http://nus.edu.sg/">National University of Singapore</a> on medical image segmentation and survival prediction problems. I graduated from <a href="https://www.nitt.edu/">NIT Trichy, India</a> in 2019 with my Bachelor's degree majoring in Instrumentation and Control.
              </p>
              
		<p>
              
              <p align=center>
                <a href="mailto:jeyamariajose7@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://drive.google.com/file/d/1QGcZlbUYvc6DmuhORwYU8GauVCwLZa9y/view?usp=sharing">CV</a> &nbsp/&nbsp
               
                <a href="https://scholar.google.co.in/citations?user=vphpzPYAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
		      <a href="https://github.com/jeya-maria-jose">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/jeya-maria-jose-357951130"> LinkedIn </a>
              </p>
            </td>
            <td width="33%">
              <img src="images/jose/dp.jpg" height = "300" width = "215">
            </td>
          </tr>
        </table>
	      
      
	      
	      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Logs</heading>
		    <p>
		    </p>
		    <div> June, 2021   -  2 papers accepted at <c href = "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=4200690" class ="text-succes"> MICCAI 2021 </c>.
		    <div>
		    <div> May, 2021   -  Joined <strong><b href = "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=4200690"> Adobe </b></strong> as a Research Intern.
		    <div>
		    <div> May, 2021   -  1 paper accepted at <c href = "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=4200690" class ="text-succes"> ICIP 2021 </c>.
		    <div>
		    <div> November, 2020   -  1 paper accepted in <c href = "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=4200690" class ="text-succes"> IEEE Journal of Selected Topics in Signal Processing </c>.
		    <div>
		    <div> November, 2020   -  1 paper accepted at <c href = "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=4200690" class ="text-succes"> WACV 2021 </c>.
		    <div>
		    <div> July, 2020   -  Recipient of <c href = "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=4200690" class ="text-succes"> MICCAI Student Travel Award </c> for the year 2020.
		    <div>
		    <div> May, 2020   -  1 paper accepted in the  <c href = "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=4200690" class ="text-succes">IEEE Journal of Selected Topics in Signal Processing </c>.
		    <div>
		     <div> May, 2020   - 1 paper accepted  at <c href = "https://www.miccai2020.org/en/" class ="text-succes"> MICCAI 2020  </c> (Early Acceptance).
		    <div>
		September, 2019 - Awarded <c href="http://cvip2019.mnit.ac.in/Award.aspx" class="text-success"> Best Student Paper award </c> at <c href = "http://cvip2019.mnit.ac.in/Default.aspx" class="text-success"> CVIP 2019 </c>. 
		    </div>
		    <div> August, 2019   -     Joined <c href = "https://www.jhu.edu/" class ="text-succes"> Johns Hopkins University </c> for my Ph.D with <c class = "text-success">ECE fellowship</c>.
              </div>
            </td>
          </tr>
        </table>

			    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Teaching</heading>
		    <p>
			   Teaching Assistant: Deep Learning EN.520.638.01.SP21, Spring 2021, Johns Hopkins University </a>
		    </p>
		   
          <tr>	
			    </table>
		  
<heading>Projects</heading>	
			    
<table width="100%" align="center" border="0" cellspacing="20" cellpadding="20">
		
		 <tr onmouseout="dpzlearn_stop()" onmouseover="dpzlearn_start()">
            <td width="35%">
              <div class="one">
                <div class="two" id='dpzlearn_image'><img src='images/jose/medt.png' height="200" width="270" ></div>
                <img src='images/jose/medt.png' height="200" width="270" >
              </div>
              <script type="text/javascript">
                function dpzlearn_start() {
                  document.getElementById('dpzlearn_image').style.opacity = "1";
                }
                function dpzlearn_stop() {
                  document.getElementById('dpzlearn_image').style.opacity = "0";
                }
                dpzlearn_stop()
              </script>
            </td>
            <td valign="middle" width="75%">
              <a href="https://arxiv.org/abs/2102.10662">
                <papertitle> Medical Transformer: Gated Axial-Attention for Medical Image Segmentation </papertitle>
              </a>
		 <div><b href="https://arxiv.org/abs/2102.10662"> MICCAI 2021 </b> 
		    </div>   
              <br>
              <p><strong><a href="https://jeya-maria-jose.github.io/research/">V Jeya Maria Jose</a></strong>,
              Poojan Oza,
		    Ilker Hacihaliloglu,
		    Vishal M. Patel
		    </p>
              
		    <p> <a href="https://arxiv.org/abs/2102.10662">Paper </a> |  <a href="https://github.com/jeya-maria-jose/Medical-Transformer"> Code </a> </p>
              <p>  Introduces Medical Transformer (MedT) built using gated axial self attention module designed to train transformers in less-data regime for medical tasks. </p>
            </td>
			 
          </tr>
	
	
		 <tr onmouseout="dpzlearn_stop()" onmouseover="dpzlearn_start()">
            <td width="35%">
              <div class="one">
                <div class="two" id='dpzlearn_image'><img src='images/jose/oucr1.png' height="200" width="270" ></div>
                <img src='images/jose/oucr2.png' height="200" width="270" >
              </div>
              <script type="text/javascript">
                function dpzlearn_start() {
                  document.getElementById('dpzlearn_image').style.opacity = "1";
                }
                function dpzlearn_stop() {
                  document.getElementById('dpzlearn_image').style.opacity = "0";
                }
                dpzlearn_stop()
              </script>
            </td>
            <td valign="middle" width="75%">
              <a href="https://arxiv.org/pdf/2106.08886.pdf">
                <papertitle> Over-and-Under Complete Convolutional RNN for MRI Reconstruction </papertitle>
              </a>
		 <div><b href="https://arxiv.org/pdf/2106.08886.pdf"> MICCAI 2021 </b> 
		    </div>   
              <br>
              <p>Pengfei Guo, <strong><a href="https://jeya-maria-jose.github.io/research/">V Jeya Maria Jose</a></strong>,
              Puyang Wang,
		    Jinyuan Zhou,Shanshan Jiang,
		    Vishal M. Patel
		    </p>
              
		    <p> <a href="https://arxiv.org/pdf/2106.08886.pdf">Paper </a> |  <a href="https://github.com/guopengf/OUCR"> Code </a> </p>
              <p> Introduces Over-and-Under Complete Convolutional Recurrent Neural Network (OUCR) for reconstructing magnetic resonance (MR) images from undersampled data. </p>
            </td>
			 
          </tr>
	
	<tr onmouseout="dpzlearn_stop()" onmouseover="dpzlearn_start()">
            <td width="35%">
              <div class="one">
                <div class="two" id='dpzlearn_image'><img src='images/jose/kiunet3d.png' height="200" width="270" ></div>
                <img src='images/jose/densekiunet.png' height="200" width="270" >
              </div>
              <script type="text/javascript">
                function dpzlearn_start() {
                  document.getElementById('dpzlearn_image').style.opacity = "1";
                }
                function dpzlearn_stop() {
                  document.getElementById('dpzlearn_image').style.opacity = "0";
                }
                dpzlearn_stop()
              </script>
            </td>
            <td valign="middle" width="75%">
              <a href="https://arxiv.org/abs/2010.01663">
                <papertitle>KiU-Net: Overcomplete Convolutional Architectures for Biomedical Image and Volumetric Segmentation</papertitle>
              </a>
		 <div><b href=""> Preprint, Under Review at IEEE TMI </b> 
		    </div>   
              <br>
		    <br>
              <p><strong><a href="https://jeya-maria-jose.github.io/research/">V Jeya Maria Jose</a></strong>,
              Vishwanath Sindagi,
		    Ilker Hacihaliloglu,
		    Vishal M. Patel
		    </p>
              
		    <p> <a href="https://arxiv.org/abs/2010.01663">Paper </a> |  <a href="https://github.com/jeya-maria-jose/KiU-Net-pytorch"> Code </a> |  <a href="https://sites.google.com/view/kiunet/kiu-net"> Project </a></p>
              <p> Introduces KiU-Net 3D for 3D volumetric segmentation from medical data with a focus on segmenting small volumes and sharp surface of 3D volumes . </p>
            </td>
             
		
		<tr onmouseout="dpzlearn_stop()" onmouseover="dpzlearn_start()">
            <td width="35%">
              <div class="one">
                <div class="two" id='dpzlearn_image'><img src='images/jose/odsc.png' height="200" width="270" ></div>
                <img src='images/jose/odsc.png' height="200" width="270" >
              </div>
              <script type="text/javascript">
                function dpzlearn_start() {
                  document.getElementById('dpzlearn_image').style.opacity = "1";
                }
                function dpzlearn_stop() {
                  document.getElementById('dpzlearn_image').style.opacity = "0";
                }
                dpzlearn_stop()
              </script>
            </td>
            <td valign="middle" width="75%">
              <a href="https:">
                <papertitle>Overcomplete Deep Subspace Clustering Networks</papertitle>
              </a>
		 <div><b href=""> WACV 2021 </b> 
		    </div>   
              <br>
              <p>
		      <strong><a href="https://jeya-maria-jose.github.io/research/">V Jeya Maria Jose</a></strong> and
		    Vishal M. Patel
		    </p>    
		    <p> <a href="https://arxiv.org/pdf/2011.08306.pdf">Paper </a> |  <a href="https://github.com/jeya-maria-jose/Overcomplete-Deep-Subspace-Clustering"> Code </a> </p>
              <p> We show that fusing the features from both undercomplete and overcomplete auto-encoder networks before passing them through the self-expressive layer enables 
to extract a more meaningful and robust representation of
the input data.  </p>
            </td>
			 
          </tr>
		 <tr onmouseout="dpzlearn_stop()" onmouseover="dpzlearn_start()">
            <td width="35%">
              <div class="one">
                <div class="two" id='dpzlearn_image'><img src='images/jose/rain.png' height="200" width="270" ></div>
                <img src='images/jose/rain.png' height="200" width="270" >
              </div>
              <script type="text/javascript">
                function dpzlearn_start() {
                  document.getElementById('dpzlearn_image').style.opacity = "1";
                }
                function dpzlearn_stop() {
                  document.getElementById('dpzlearn_image').style.opacity = "0";
                }
                dpzlearn_stop()
              </script>
            </td>
            <td valign="middle" width="75%">
              <a href="https://arxiv.org/abs/2010.10661">
                <papertitle>Exploring Overcomplete Representations for Single Image Deraining using CNNs</papertitle>
              </a>
		 <div><b href=""> IEEE Journal of Selected Topics in Signal Processing</b> 
		    </div>   
              <br>
              <p>Rajeev Yasarla<strong><a href="">*</a></strong>,
		      <strong><a href="https://jeya-maria-jose.github.io/research/">V Jeya Maria Jose*</a></strong>,
		    Vishal M. Patel
		    </p>   
		    <p> *equal contribution </p>
		    <p> <a href="https://arxiv.org/abs/2010.10661">Paper </a> |  <a href="https://github.com/jeya-maria-jose/Derain_OUCD_Net"> Code </a> </p>
              <p> Introduces an overcomplete convolutional network architecture which gives special attention in learning local structures like rain drops and streaks more efficiently for single image deraining.  </p>
            </td>
			 
          </tr>
		
		 <tr onmouseout="dpzlearn_stop()" onmouseover="dpzlearn_start()">
            <td width="35%">
              <div class="one">
                <div class="two" id='dpzlearn_image'><img src='images/kiu.png' height="200" width="270" ></div>
                <img src='images/kiu.png' height="200" width="270" >
              </div>
              <script type="text/javascript">
                function dpzlearn_start() {
                  document.getElementById('dpzlearn_image').style.opacity = "1";
                }
                function dpzlearn_stop() {
                  document.getElementById('dpzlearn_image').style.opacity = "0";
                }
                dpzlearn_stop()
              </script>
            </td>
            <td valign="middle" width="75%">
              <a href="https://arxiv.org/abs/2006.04878">
                <papertitle>KiU-Net: Towards Accurate Segmentation of Biomedical Images using Over-complete Representations </papertitle>
              </a>
		 <div><b href="https://arxiv.org/abs/2006.04878"> MICCAI 2020 </b> 
		    </div>   
              <br>
              <p><strong><a href="https://jeya-maria-jose.github.io/research/">V Jeya Maria Jose</a></strong>,
              Vishwanath Sindagi,
		    Ilker Hacihaliloglu,
		    Vishal M. Patel
		    </p>
              
		    <p> <a href="https://arxiv.org/abs/2006.04878">Paper </a> |  <a href="https://github.com/jeya-maria-jose/KiU-Net-pytorch"> Code </a> |  <a href="https://sites.google.com/view/kiunet/kiu-net"> Project </a></p>
              <p> We introduce KiU-Net, a multi-branch network where we constraint the receptive field from expanding in the deep layers and thus learning fine details for precise segmentation of both small and big landmarks by using overcomplete representations.  </p>
            </td>
			 
          </tr>
		
		 <tr onmouseout="dpzlearn_stop()" onmouseover="dpzlearn_start()">
            <td width="35%">
              <div class="one">
                <div class="two" id='dpzlearn_image'><img src='images/jose/CBAS.png' height="200" width="270" ></div>
                <img src='images/jose/mssa.png' height="200" width="270" >
              </div>
              <script type="text/javascript">
                function dpzlearn_start() {
                  document.getElementById('dpzlearn_image').style.opacity = "1";
                }
                function dpzlearn_stop() {
                  document.getElementById('dpzlearn_image').style.opacity = "0";
                }
                dpzlearn_stop()
              </script>
            </td>
            <td valign="middle" width="75%">
              <a href="https://arxiv.org/abs/1912.08364">
                <papertitle>Learning to Segment Brain Anatomy from 2D Ultrasound with Less Data </papertitle>
              </a>
		 <div><b href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=4200690"> IEEE Journal of Selected Topics in Signal Processing  </b> 
		    </div>   
              <br>
              <p><strong><a href="https://jeya-maria-jose.github.io/research/">V Jeya Maria Jose</a></strong>,
              Rajeev Yasarla,
		    Puyang Wang,
		    Ilker Hacihaliloglu,
		    Vishal M. Patel
		    </p>
              
		    <p> <a href="https://arxiv.org/abs/1912.08364">Paper </a></p>
              <p> Two deep networks, a Multi-Scale Self Attention (MSSA) network for synthesis and a Confidence Based Brain Anatomy (CBAS) network for segmentation has been proposed for ultrasound modality achieving state of the art performance in each of their tasks. Moreover, we show how synthesis aids the segmentation even with less data.  </p>
            </td>
			 
          </tr>
		
          <tr onmouseout="porlight_stop()" onmouseover="porlight_start()">
            <td width="35%">
              <div class="one">
                <div class="two" id='porlight_image'><img src='images/jose/103_fake_B.png'height="200" width="200"></div>
                <img src='images/jose/103_real_A.png' height="200" width="200">
              </div>
              <script type="text/javascript">
                function porlight_start() {
                  document.getElementById('porlight_image').style.opacity = "1";
                }
                function porlight_stop() {
                  document.getElementById('porlight_image').style.opacity = "0";
                }
                porlight_stop()
              </script>
            </td>
            <td valign="middle" width="75%">
              <a href="https://link.springer.com/chapter/10.1007/978-981-15-4018-9_30">
                 <papertitle> Tackling Multiple Visual Artifacts: Blind Image Restoration using Conditional Adversarial Networks </papertitle> 
              </a>        
		<div><b href="http://cvip2019.mnit.ac.in/"> CVIP 2019 </b> <font color="red"><b href="http://cvip2019.mnit.ac.in/Award.aspx"> (Best Student Paper Award) </b></font> 
		    </div>
			<br>    
              M Anand,
              A Ashwin Natraj,
	      <strong><a href="https://jeya-maria-jose.github.io/research/">V Jeya Maria Jose</a></strong>,
              K Subramanian,
              S Deivalakshmi    
		    </p><a href="https://link.springer.com/chapter/10.1007/978-981-15-4018-9_30"> Paper </a> | <a href="https://github.com/jeya-maria-jose/Image-Recovery-Using-Conditional-Adversarial-Networks"> Code </a></p>
		
		<p> Restoring images that are degraded by multiple visual artifacts like noise, blurness and other environmental visual artifacts like shadow, snow, rain and haze is a challenging task. In this work, use of conditional adversarial networks for this task has been explored.  </p>
            </td>
          </tr>
	   <tr onmouseout="dpzlearn_stop()" onmouseover="dpzlearn_start()">
            <td width="35%">
              <div class="one">
                <div class="two" id='dpzlearn_image'><img src='images/jose/arch3datn.png' height="200" width="270" ></div>
                <img src='images/jose/brain.png' height="200" width="270" >
              </div>
              <script type="text/javascript">
                function dpzlearn_start() {
                  document.getElementById('dpzlearn_image').style.opacity = "1";
                }
                function dpzlearn_stop() {
                  document.getElementById('dpzlearn_image').style.opacity = "0";
                }
                dpzlearn_stop()
              </script>
            </td>
            <td valign="middle" width="75%">
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-46640-4_25">
                <papertitle>Brain Tumor Segmentation and Survival Prediction using 3D Attention UNet </papertitle>
              </a>
		    <div><b href="https://www.med.upenn.edu/cbica/brats2019/registration.html" class="text-danger">BraTS, </b> <b href="http://www.brainlesion-workshop.org/"> MICCAI Workshop 2019 </b></div>
              <br>
		    Mobarakol Islam,
		    Vibashan VS,
		    <strong><a href="https://jeya-maria-jose.github.io/research/">V Jeya Maria Jose</a></strong>,
		    Navodini Wijethilake,
		    Uppal Utkarsh,
		    Hongliang Ren
             
              
		    <p> <a href="https://link.springer.com/chapter/10.1007/978-3-030-46640-4_25">Paper </a></p>
              <p> We adopt a 3D UNet architecture and integrate channel and spatial attention with the decoder network to perform segmen-tation. For survival prediction, we extract some novel radiomic featuresbased on geometry, location, the shape of the segmented tumor and com-bine them with clinical information to estimate the survival duration for each patient. </p>
            </td>
          </tr>
          <tr onmouseout="dpzlearn_stop()" onmouseover="dpzlearn_start()">
            <td width="35%">
              <div class="one">
                <div class="two" id='dpzlearn_image'><img src='images/jose/cuff.gif' height="240" width="240" ></div>
                <img src='images/jose/cuff.gif' height="240" width="240" >
              </div>
              <script type="text/javascript">
                function dpzlearn_start() {
                  document.getElementById('dpzlearn_image').style.opacity = "1";
                }
                function dpzlearn_stop() {
                  document.getElementById('dpzlearn_image').style.opacity = "0";
                }
                dpzlearn_stop()
              </script>
            </td>
            <td valign="middle" width="75%">
              <a href="https://arxiv.org/abs/190822">
                <papertitle>BP-Net: Cuff-less Blood Pressure Prediction using Convolutional and Long Short-term Memory Networks from ECG and PPG signals  </papertitle>
              </a>
		    <div> <b Elsevier Biomedical Signal Processing and Control ></b></div>

              <br>
              <p><strong><a href="https://jeya-maria-jose.github.io/research/">V Jeya Maria Jose</a></strong>,
              M Anand,
              Geerthy T,
	      M Siddarth,
		K Subramanian,
		    G Uma
		    </p>
		    <p>  <a href="https://www.sciencedirect.com/science/article/abs/pii/S1746809420300987">Paper (Feature Analysis using ML) </a> | <a href="https://github.com/jeya-maria-jose/Cuff_less_BP_Prediction">Code </a> | Paper (BP-Net) - Coming Soon</p>
              <p> An approach that does not need calibration or manual feature extraction is proposed using CNNs and LSTMs for BP prediction from ECG and PPG signals. </p>
            </td>
          </tr>
	  <tr onmouseout="cuff_stop()" onmouseover="cuff_start()">
            <td width="35%">
              <div class="one">
                <div class="two" id='cuff_image'><img src='images/jose/op.PNG' height="200" width="200" ></div>
                <img src='images/jose/brats.gif' height="200" width="200" >
              </div>
              <script type="text/javascript">
                function cuff_start() {
                  document.getElementById('cuff_image').style.opacity = "1";
                }
                function cuff_stop() {
                  document.getElementById('cuff_image').style.opacity = "0";
                }
                cuff_stop()
              </script>
            </td>
            <td valign="middle" width="75%">
              <a href="https://arxiv.og/as/19022">
                <papertitle>Glioma Prognosis: Segmentation of the Tumor and Survival Prediction using Shape, Geometric and Clinical Information </papertitle>
              </a>
		    <div><b href="https://www.med.upenn.edu/cbica/brats2019/registration.html" class="text-danger">BraTS, </b> <b href="http://www.brainlesion-workshop.org/"> MICCAI Workshop 2018 </b></div>
              <br>
		Mobarakol Islam,
              <strong><a href="https://jeya-maria-jose.github.io/research/">V Jeya Maria Jose</a></strong>,
              Hongliang Ren
              
		    <p><a href="https://link.springer.com/chapter/10.1007/978-3-030-11726-9_13">Paper</a>  | <a href="https://drive.google.com/open?id=1e5CjKuY2dfRlT5ZEMWl0u1oehvMe_TEy">Poster</a></p>
              <p>Segmentation of brain tumor from magnetic resonance imaging (MRI) is performed using a convolutional neural network (CNN) with hypercolumn technique. Also, a variety of features are extracted from the segmented tumor to predict the overall survival in terms of number of days for each patient.   </p>
            </td>
          </tr>
	  <tr onmouseout="is_stop()" onmouseover="is_start()">
            <td width="35%">
              <div class="one">
                <div class="two" id='is_image'><img src='images/jose/isop.PNG' height="200" width="200" ></div>
                <img src='images/jose/isip.PNG' height="200" width="200" >
              </div>
              <script type="text/javascript">
                function is_start() {
                  document.getElementById('is_image').style.opacity = "1";
                }
                function is_stop() {
                  document.getElementById('is_image').style.opacity = "0";
                }
                is_stop()
              </script>
            </td>
            <td valign="middle" width="75%">
            <a href="https://arxiv.og/abs/1904.0522">
                <papertitle>Ischemic Stroke Lesion Segmentation Using Adversarial Learning </papertitle>
		    </a>
              <br>
		    <div><b href="https://www.med.upenn.edu/cbica/brats2019/registration.html" class="text-danger">ISLES, </b> <b href="http://www.brainlesion-workshop.org/"> MICCAI Workshop 2018 </b></div>
		<p>Mobarakol Islam,
		    Rajiv V,
              <strong><a href="https://jeya-maria-jose.github.io/research/">V Jeya Maria Jose</a></strong>,
			Hongliang Ren</p>
              
		    <p><a href="https://link.springer.com/chapter/10.1007/978-3-030-11723-8_29">Paper</a></p>
              <p> A segmentation model with adversarial learning for ischemic lesion segmentation. U-Net with skip connection and dropout is adopted as segmentation baseline network and a fully convolutional network (FCN) is used as discriminator network. Three modalities (CT, DPWI, CBF) of acute computed tomography (CT) perfusion data was used to train the net.   </p>
            </td>
          </tr>
	
		
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Services</heading>
		    <p>
			    Web Chair: <a href="http://www.avss2021.org/">AVSS 2021</a>
		    </p>
		    <p>
			    Reviewer at:
		    </p>
		    <div> Journals : IEEE - TMI, TCSVT; Springer - IJCV; Elsevier - PR, CBM
		    <div>
			<div> Conferences : ICCV, ICLR, MICCAI, WACV, ICIP
		    <div>
			    <div> Workshops : BrainLes,  Medical Image Learning with Less Labels and Imperfect Data
		    <div>
		 <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
			<a href="https://github.com/jonbarron/jonbarron_website">source code</a> </p>
			
      <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=f5f4f4&w=a&t=tt&d=4oNS7GMLzd6uqlifXXoWHJs7VBLH4fPNor9WNhD_QWQ&co=2d5f82&cmn=5a38bd'></script>
</html>
